{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "df = df[:50000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    47730\n",
       "Word              0\n",
       "POS               0\n",
       "Tag               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2270, 7464, 17)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill NaN by preceding values\n",
    "df = df.fillna(method='ffill')\n",
    "df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>war</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demand</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>troops</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>country</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49970</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>rebels</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49971</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49972</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49973</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49974</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>local</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49975</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>villagers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49976</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49977</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49978</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>elephants</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49979</th>\n",
       "      <td>Sentence: 2269</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49980</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>group</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49982</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>blames</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49983</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49984</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>surge</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49985</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49986</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>poaching</td>\n",
       "      <td>VBG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49987</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>on</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49988</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49989</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>liberalization</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49990</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49992</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>ivory</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49993</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>trade</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49994</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>being</td>\n",
       "      <td>VBG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>pushed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>by</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>South</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Sentence: 2270</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sentence #            Word  POS    Tag\n",
       "0         Sentence: 1       Thousands  NNS      O\n",
       "1         Sentence: 1              of   IN      O\n",
       "2         Sentence: 1   demonstrators  NNS      O\n",
       "3         Sentence: 1            have  VBP      O\n",
       "4         Sentence: 1         marched  VBN      O\n",
       "5         Sentence: 1         through   IN      O\n",
       "6         Sentence: 1          London  NNP  B-geo\n",
       "7         Sentence: 1              to   TO      O\n",
       "8         Sentence: 1         protest   VB      O\n",
       "9         Sentence: 1             the   DT      O\n",
       "10        Sentence: 1             war   NN      O\n",
       "11        Sentence: 1              in   IN      O\n",
       "12        Sentence: 1            Iraq  NNP  B-geo\n",
       "13        Sentence: 1             and   CC      O\n",
       "14        Sentence: 1          demand   VB      O\n",
       "15        Sentence: 1             the   DT      O\n",
       "16        Sentence: 1      withdrawal   NN      O\n",
       "17        Sentence: 1              of   IN      O\n",
       "18        Sentence: 1         British   JJ  B-gpe\n",
       "19        Sentence: 1          troops  NNS      O\n",
       "20        Sentence: 1            from   IN      O\n",
       "21        Sentence: 1            that   DT      O\n",
       "22        Sentence: 1         country   NN      O\n",
       "23        Sentence: 1               .    .      O\n",
       "24        Sentence: 2        Families  NNS      O\n",
       "25        Sentence: 2              of   IN      O\n",
       "26        Sentence: 2        soldiers  NNS      O\n",
       "27        Sentence: 2          killed  VBN      O\n",
       "28        Sentence: 2              in   IN      O\n",
       "29        Sentence: 2             the   DT      O\n",
       "...               ...             ...  ...    ...\n",
       "49970  Sentence: 2269          rebels  NNS      O\n",
       "49971  Sentence: 2269               ,    ,      O\n",
       "49972  Sentence: 2269        soldiers  NNS      O\n",
       "49973  Sentence: 2269             and   CC      O\n",
       "49974  Sentence: 2269           local   JJ      O\n",
       "49975  Sentence: 2269       villagers  NNS      O\n",
       "49976  Sentence: 2269          killed  VBD      O\n",
       "49977  Sentence: 2269             the   DT      O\n",
       "49978  Sentence: 2269       elephants  NNS      O\n",
       "49979  Sentence: 2269               .    .      O\n",
       "49980  Sentence: 2270             The   DT      O\n",
       "49981  Sentence: 2270           group   NN      O\n",
       "49982  Sentence: 2270          blames  VBZ      O\n",
       "49983  Sentence: 2270             the   DT      O\n",
       "49984  Sentence: 2270           surge   NN      O\n",
       "49985  Sentence: 2270              in   IN      O\n",
       "49986  Sentence: 2270        poaching  VBG      O\n",
       "49987  Sentence: 2270              on   IN      O\n",
       "49988  Sentence: 2270             the   DT      O\n",
       "49989  Sentence: 2270  liberalization   NN      O\n",
       "49990  Sentence: 2270              of   IN      O\n",
       "49991  Sentence: 2270             the   DT      O\n",
       "49992  Sentence: 2270           ivory   NN      O\n",
       "49993  Sentence: 2270           trade   NN      O\n",
       "49994  Sentence: 2270           being  VBG      O\n",
       "49995  Sentence: 2270          pushed  VBN      O\n",
       "49996  Sentence: 2270              by   IN      O\n",
       "49997  Sentence: 2270           South  NNP  B-geo\n",
       "49998  Sentence: 2270          Africa  NNP  I-geo\n",
       "49999  Sentence: 2270               ,    ,      O\n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Tag\"].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-art</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-eve</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-geo</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-gpe</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-nat</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-org</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B-per</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-tim</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-art</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-eve</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-geo</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-gpe</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I-nat</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I-org</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I-per</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I-tim</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O</td>\n",
       "      <td>42547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag  count\n",
       "0   B-art     48\n",
       "1   B-eve     39\n",
       "2   B-geo   1490\n",
       "3   B-gpe    968\n",
       "4   B-nat     18\n",
       "5   B-org    959\n",
       "6   B-per    789\n",
       "7   B-tim    880\n",
       "8   I-art     27\n",
       "9   I-eve     33\n",
       "10  I-geo    303\n",
       "11  I-gpe     31\n",
       "12  I-nat      9\n",
       "13  I-org    689\n",
       "14  I-per    931\n",
       "15  I-tim    239\n",
       "16      O  42547"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Tag').size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33500, 9774), (33500,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Tag', axis=1)\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(X.to_dict('records'))\n",
    "y = df.Tag.values\n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "-- Epoch 1-- Epoch 1\n",
      "-- Epoch 1\n",
      "\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 40.36, NNZs: 932, Bias: -3.000000, T: 33500, Avg. loss: 0.020746\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 50.47, NNZs: 1434, Bias: -5.000000, T: 33500, Avg. loss: 0.042269\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 7.21, NNZs: 49, Bias: -2.000000, T: 33500, Avg. loss: 0.000955\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 42.87, NNZs: 1146, Bias: -4.000000, T: 33500, Avg. loss: 0.036328\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 10.34, NNZs: 101, Bias: -3.000000, T: 33500, Avg. loss: 0.002030\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 1Norm: 35.41, NNZs: 871, Bias: -4.000000, T: 33500, Avg. loss: 0.024149\n",
      "\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 35.31, NNZs: 695, Bias: -3.000000, T: 33500, Avg. loss: 0.017612\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 10.20, NNZs: 77, Bias: -4.000000, T: 33500, Avg. loss: 0.001433\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  17 | elapsed:    1.4s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  17 | elapsed:    1.4s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  17 | elapsed:    1.5s remaining:    1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 9.70, NNZs: 80, Bias: -4.000000, T: 33500, Avg. loss: 0.001224\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 9.64, NNZs: 76, Bias: -3.000000, T: 33500, Avg. loss: 0.001164Norm: 6.16, NNZs: 27, Bias: -2.000000, T: 33500, Avg. loss: 0.000209\n",
      "Total training time: 1.30 seconds.\n",
      "Total training time: 1.30 seconds.\n",
      "\n",
      "Norm: 24.43, NNZs: 417, Bias: -3.000000, T: 33500, Avg. loss: 0.010478\n",
      "Total training time: 1.35 seconds.\n",
      "Norm: 8.66, NNZs: 63, Bias: -3.000000, T: 33500, Avg. loss: 0.001313\n",
      "Total training time: 1.38 seconds.\n",
      "Norm: 21.84, NNZs: 341, Bias: -3.000000, T: 33500, Avg. loss: 0.009881\n",
      "Total training time: 1.26 seconds.\n",
      "Norm: 38.47, NNZs: 860, Bias: -6.000000, T: 33500, Avg. loss: 0.023343\n",
      "Total training time: 1.41 seconds.\n",
      "Norm: 44.52, NNZs: 1248, Bias: -6.000000, T: 33500, Avg. loss: 0.028746\n",
      "Total training time: 1.40 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  17 | elapsed:    2.7s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    2.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.8s remaining:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 51.33, NNZs: 1478, Bias: 3.000000, T: 33500, Avg. loss: 0.046090\n",
      "Total training time: 0.52 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=5, n_iter_no_change=5, n_jobs=-1,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "per.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.75      0.17      0.27        18\n",
      "       B-eve       0.00      0.00      0.00        14\n",
      "       B-geo       0.76      0.39      0.52       476\n",
      "       B-gpe       0.26      0.82      0.39       320\n",
      "       B-nat       0.00      0.00      0.00         3\n",
      "       B-org       0.56      0.45      0.50       301\n",
      "       B-per       0.68      0.47      0.55       258\n",
      "       B-tim       0.86      0.75      0.81       272\n",
      "       I-art       0.00      0.00      0.00         5\n",
      "       I-eve       0.67      0.36      0.47        11\n",
      "       I-geo       0.36      0.60      0.45       115\n",
      "       I-gpe       0.00      0.00      0.00        11\n",
      "       I-nat       0.50      0.33      0.40         3\n",
      "       I-org       0.81      0.23      0.36       200\n",
      "       I-per       0.86      0.08      0.15       306\n",
      "       I-tim       0.44      0.09      0.15        90\n",
      "\n",
      "   micro avg       0.48      0.44      0.46      2403\n",
      "   macro avg       0.47      0.30      0.31      2403\n",
      "weighted avg       0.65      0.44      0.45      2403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaghlol/Projects/NER/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=per.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.50      0.11      0.18        18\n",
      "       B-eve       0.00      0.00      0.00        14\n",
      "       B-geo       0.47      0.89      0.61       476\n",
      "       B-gpe       0.95      0.53      0.68       320\n",
      "       B-nat       0.00      0.00      0.00         3\n",
      "       B-org       0.79      0.26      0.39       301\n",
      "       B-per       0.76      0.38      0.51       258\n",
      "       B-tim       0.92      0.71      0.80       272\n",
      "       I-art       0.50      0.20      0.29         5\n",
      "       I-eve       0.36      0.36      0.36        11\n",
      "       I-geo       0.85      0.30      0.44       115\n",
      "       I-gpe       0.00      0.00      0.00        11\n",
      "       I-nat       0.00      0.00      0.00         3\n",
      "       I-org       0.65      0.35      0.46       200\n",
      "       I-per       0.47      0.73      0.57       306\n",
      "       I-tim       0.40      0.02      0.04        90\n",
      "\n",
      "   micro avg       0.60      0.54      0.57      2403\n",
      "   macro avg       0.48      0.30      0.33      2403\n",
      "weighted avg       0.68      0.54      0.54      2403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaghlol/Projects/NER/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.09      0.28      0.13        18\n",
      "       B-eve       0.29      0.29      0.29        14\n",
      "       B-geo       0.66      0.58      0.62       476\n",
      "       B-gpe       0.65      0.73      0.68       320\n",
      "       B-nat       0.18      0.67      0.29         3\n",
      "       B-org       0.48      0.48      0.48       301\n",
      "       B-per       0.38      0.48      0.42       258\n",
      "       B-tim       0.60      0.72      0.65       272\n",
      "       I-art       0.08      0.20      0.12         5\n",
      "       I-eve       0.47      0.64      0.54        11\n",
      "       I-geo       0.43      0.49      0.46       115\n",
      "       I-gpe       0.00      0.00      0.00        11\n",
      "       I-nat       0.00      0.00      0.00         3\n",
      "       I-org       0.47      0.48      0.48       200\n",
      "       I-per       0.52      0.45      0.49       306\n",
      "       I-tim       0.16      0.26      0.20        90\n",
      "\n",
      "   micro avg       0.50      0.54      0.52      2403\n",
      "   macro avg       0.34      0.42      0.36      2403\n",
      "weighted avg       0.52      0.54      0.53      2403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels = new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                            early_stopping=False, fit_intercept=True,\n",
       "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
       "                            n_jobs=None, random_state=None, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa =PassiveAggressiveClassifier()\n",
    "pa.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.50      0.17      0.25        18\n",
      "       B-eve       0.18      0.21      0.19        14\n",
      "       B-geo       0.70      0.66      0.68       476\n",
      "       B-gpe       0.85      0.58      0.69       320\n",
      "       B-nat       0.00      0.00      0.00         3\n",
      "       B-org       0.64      0.40      0.49       301\n",
      "       B-per       0.43      0.55      0.48       258\n",
      "       B-tim       0.91      0.69      0.78       272\n",
      "       I-art       0.00      0.00      0.00         5\n",
      "       I-eve       0.50      0.27      0.35        11\n",
      "       I-geo       0.50      0.50      0.50       115\n",
      "       I-gpe       1.00      0.09      0.17        11\n",
      "       I-nat       0.27      1.00      0.43         3\n",
      "       I-org       0.70      0.32      0.44       200\n",
      "       I-per       0.44      0.67      0.53       306\n",
      "       I-tim       0.41      0.29      0.34        90\n",
      "\n",
      "   micro avg       0.60      0.55      0.57      2403\n",
      "   macro avg       0.50      0.40      0.40      2403\n",
      "weighted avg       0.65      0.55      0.58      2403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=pa.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
    "                                                           s['POS'].values.tolist(), \n",
    "                                                           s['Tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.50      0.05      0.10        19\n",
      "       B-eve       0.71      0.29      0.42        17\n",
      "       B-geo       0.67      0.86      0.75       475\n",
      "       B-gpe       0.83      0.73      0.78       334\n",
      "       B-nat       0.00      0.00      0.00         5\n",
      "       B-org       0.71      0.57      0.63       354\n",
      "       B-per       0.79      0.79      0.79       243\n",
      "       B-tim       0.87      0.86      0.87       291\n",
      "       I-art       0.00      0.00      0.00        12\n",
      "       I-eve       1.00      0.25      0.40        16\n",
      "       I-geo       0.65      0.65      0.65        92\n",
      "       I-gpe       0.00      0.00      0.00         9\n",
      "       I-nat       0.00      0.00      0.00         1\n",
      "       I-org       0.77      0.76      0.76       254\n",
      "       I-per       0.84      0.93      0.88       283\n",
      "       I-tim       0.71      0.62      0.66        88\n",
      "\n",
      "   micro avg       0.76      0.75      0.76      2493\n",
      "   macro avg       0.56      0.46      0.48      2493\n",
      "weighted avg       0.75      0.75      0.75      2493\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaghlol/Projects/NER/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-geo  -> I-geo   6.025124\n",
      "B-per  -> I-per   5.752572\n",
      "I-tim  -> I-tim   5.537304\n",
      "B-org  -> I-org   5.377582\n",
      "I-org  -> I-org   5.225950\n",
      "B-tim  -> I-tim   5.203619\n",
      "B-gpe  -> I-gpe   4.811577\n",
      "I-per  -> I-per   4.570931\n",
      "B-art  -> I-art   4.515261\n",
      "B-eve  -> I-eve   4.346047\n",
      "I-gpe  -> I-gpe   4.146536\n",
      "I-geo  -> I-geo   4.096209\n",
      "I-art  -> I-art   3.888031\n",
      "O      -> O       3.750474\n",
      "B-nat  -> I-nat   3.301682\n",
      "I-eve  -> I-eve   3.097023\n",
      "B-org  -> B-art   2.426228\n",
      "I-nat  -> I-nat   1.998332\n",
      "O      -> B-eve   1.883422\n",
      "O      -> B-per   1.803690\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-geo  -> B-per   -1.034029\n",
      "B-org  -> I-per   -1.076155\n",
      "I-tim  -> B-tim   -1.083762\n",
      "B-geo  -> I-org   -1.174412\n",
      "B-geo  -> I-per   -1.183731\n",
      "B-gpe  -> I-org   -1.188898\n",
      "I-org  -> I-per   -1.284712\n",
      "B-org  -> B-org   -1.326719\n",
      "B-gpe  -> I-geo   -1.380641\n",
      "B-tim  -> B-tim   -1.421861\n",
      "O      -> I-art   -1.550078\n",
      "B-tim  -> B-gpe   -1.830413\n",
      "B-geo  -> B-per   -2.019120\n",
      "B-per  -> B-per   -2.047799\n",
      "B-gpe  -> B-gpe   -2.106184\n",
      "I-per  -> B-per   -2.153230\n",
      "O      -> I-per   -2.772301\n",
      "O      -> I-tim   -2.980650\n",
      "O      -> I-geo   -3.154170\n",
      "O      -> I-org   -3.307300\n"
     ]
    }
   ],
   "source": [
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
